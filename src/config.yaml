embedding:
  model_name: "BAAI/bge-large-en-v1.5"  # Best overall but more sensitive to numerical data
  normalize: true
  preprocess_e5: true

llms:
  default: "llama3.2:3b"
  default_context_window: 32768
  available:
    - qwen3:4b
    - phi3:3.8b
    - gemma3:4b
  temperature: 0.0
  top_k: 1
  top_p: 1.0
  repeat_penalty: 1.0
  seed: 42
  

server:
  host: "0.0.0.0"
  port: 1299
  log_level: "info"

endpoints:
 ollama: "http://leetllama_ollama:11434/api/chat"
 rag_service: "http://leetllama_rag_service:1299/api/rag-retrieve"
 milvus: "tcp://standalone:19530"

rag_config:
  collection_name: "leetcode_kb"
  top_k: 3
  score_threshold: 0.4

vstore:
  host: "localhost"
  port: "19530"