include:
  - ./compose/milvus-standalone-docker-compose-gpu.yml

services:

  ollama:
    image: ollama/ollama:0.9.5
    container_name: leetllama_ollama
    ports:
      - "1290:11434"  # Host:Container
    volumes:
      - ./models:/root/.ollama/models  # Reuse already-downloaded models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: ["gpu"]
              device_ids: ["0"]
    runtime: nvidia

    environment:
      - NVIDIA_VISIBLE_DEVICES=0
      - OLLAMA_ORCHESTRATOR=api

    networks:
      - leetllama_net

    depends_on:
      - "standalone"


networks:
  leetllama_net:
    driver: bridge